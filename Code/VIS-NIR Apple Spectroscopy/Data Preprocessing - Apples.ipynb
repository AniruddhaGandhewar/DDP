{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT REQUIRED LIBRARIES\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT RAW DATA\n",
    "\n",
    "spectra_path_1 = \"C:\\\\Users\\\\argan\\\\OneDrive\\\\Desktop\\\\DDP\\\\Data 2\\\\Spectra 1\"\n",
    "spectra_path_2 = \"C:\\\\Users\\\\argan\\\\OneDrive\\\\Desktop\\\\DDP\\\\Data 2\\\\Spectra 2\"\n",
    "spectra_path_3 = \"C:\\\\Users\\\\argan\\\\OneDrive\\\\Desktop\\\\DDP\\\\Data 2\\\\NewAppleFiles\"\n",
    "\n",
    "brix_vals_path = \"C:\\\\Users\\\\argan\\\\OneDrive\\\\Desktop\\\\DDP\\\\Data 2\\\\BrixVal3.xlsx\"\n",
    "brix_vals_path_3 = \"C:\\\\Users\\\\argan\\\\OneDrive\\\\Desktop\\\\DDP\\\\Data 2\\\\NewBrixValues.xlsx\"\n",
    "\n",
    "spectra_files_1 = os.listdir(spectra_path_1)\n",
    "spectra_files_2 = os.listdir(spectra_path_2)\n",
    "spectra_files_3 = os.listdir(spectra_path_3)\n",
    "\n",
    "brix_vals = pd.read_excel(brix_vals_path, index_col=\"File\")\n",
    "brix_vals_3 = pd.read_excel(brix_vals_path_3, index_col=\"File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference Spectrum\n",
    "\n",
    "r_spectrum = pd.read_csv(spectra_path_1+\"\\\\\"+\"WhiteD1.csv\")\n",
    "r_spectrum = r_spectrum.mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging intensity readings\n",
    "\n",
    "spectra_1 = []\n",
    "brix_1 = []\n",
    "names_1 = []\n",
    "groups_1 = []\n",
    "\n",
    "sample_names = set(brix_vals.index)\n",
    "\n",
    "for file in spectra_files_1:\n",
    "    sample_name = file.split('.')[0]\n",
    "\n",
    "    # Discard file if brix value not found.\n",
    "    if sample_name.lower() not in sample_names:\n",
    "        continue\n",
    "\n",
    "    brix_val, group = brix_vals.loc[sample_name.lower()]\n",
    "\n",
    "    # Discard file if brix value type is invalid.\n",
    "    if isinstance(brix_val, str) or np.isnan(brix_val):\n",
    "        continue\n",
    "        \n",
    "    spectrum = pd.read_csv(spectra_path_1+\"\\\\\"+file, header=None, skiprows=2)\n",
    "    \n",
    "    if spectrum.shape[1] == 19:\n",
    "        spectrum = spectrum.iloc[:, :-1]\n",
    "\n",
    "    spectrum = spectrum.mean().values\n",
    "\n",
    "    names_1.append(sample_name)\n",
    "    spectra_1.append(spectrum)\n",
    "    brix_1.append(float(brix_val))\n",
    "    groups_1.append(group)\n",
    "\n",
    "wavelengths = pd.read_csv(spectra_path_1+\"\\\\\"+file).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging intensity readings\n",
    "\n",
    "spectra_2 = []\n",
    "brix_2 = []\n",
    "names_2 = []\n",
    "groups_2 = []\n",
    "\n",
    "for file in spectra_files_2:\n",
    "    sample_name = file.split('.')[0]\n",
    "\n",
    "    # Discard file if brix value not found.\n",
    "    if sample_name.lower() not in sample_names:\n",
    "        continue\n",
    "\n",
    "    brix_val, group = brix_vals.loc[sample_name.lower()]\n",
    "    \n",
    "    # Discard file if brix value type is invalid.\n",
    "    if isinstance(brix_val, str) or np.isnan(brix_val):\n",
    "        continue\n",
    "        \n",
    "    spectrum = pd.read_csv(spectra_path_2+\"\\\\\"+file, header=None, skiprows=2)\n",
    "    \n",
    "    if spectrum.shape[1] == 19:\n",
    "        spectrum = spectrum.iloc[:, :-1]\n",
    "\n",
    "    spectrum = spectrum.mean().values\n",
    "\n",
    "    names_2.append(sample_name)\n",
    "    spectra_2.append(spectrum)\n",
    "    brix_2.append(float(brix_val))\n",
    "    groups_2.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging intensity readings\n",
    "\n",
    "spectra_3 = []\n",
    "brix_3 = []\n",
    "names_3 = []\n",
    "groups_3 = []\n",
    "\n",
    "sample_names = set(brix_vals_3.index)\n",
    "\n",
    "for file in spectra_files_3:\n",
    "    sample_name = file.split('.')[0]\n",
    "\n",
    "    # Discard file if brix value not found.\n",
    "    if sample_name.lower() not in sample_names:\n",
    "        continue\n",
    "\n",
    "    brix_val, group = brix_vals_3.loc[sample_name.lower()]\n",
    "    \n",
    "    # Discard file if brix value type is invalid.\n",
    "    if isinstance(brix_val, str) or np.isnan(brix_val):\n",
    "        continue\n",
    "        \n",
    "    spectrum = pd.read_csv(spectra_path_3+\"\\\\\"+file, header=None, skiprows=2)\n",
    "    \n",
    "    if spectrum.shape[1] == 19:\n",
    "        spectrum = spectrum.iloc[:, :-1]\n",
    "\n",
    "    spectrum = spectrum.mean().values\n",
    "\n",
    "    names_3.append(sample_name)\n",
    "    spectra_3.append(spectrum)\n",
    "    brix_3.append(float(brix_val))\n",
    "    groups_3.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating absorbance values\n",
    "abs_spectra = []\n",
    "for i in range(len(spectra_1)):\n",
    "    abs_spectra.append(-np.log10(np.divide(spectra_1[i], r_spectrum)))\n",
    "\n",
    "abs_df_1 = pd.DataFrame(abs_spectra, columns=wavelengths)\n",
    "abs_df_1[\"Name\"] = names_1\n",
    "abs_df_1[\"Brix Values\"] = brix_1\n",
    "abs_df_1[\"Group\"] = groups_1\n",
    "\n",
    "abs_df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating absorbance values\n",
    "abs_spectra = []\n",
    "for i in range(len(spectra_2)):\n",
    "    abs_spectra.append(-np.log10(np.divide(spectra_2[i], r_spectrum)))\n",
    "\n",
    "abs_df_2 = pd.DataFrame(abs_spectra, columns=wavelengths)\n",
    "abs_df_2[\"Name\"] = names_2\n",
    "abs_df_2[\"Brix Values\"] = brix_2\n",
    "abs_df_2[\"Group\"] = groups_2\n",
    "\n",
    "abs_df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating absorbance values\n",
    "abs_spectra = []\n",
    "for i in range(len(spectra_3)):\n",
    "    abs_spectra.append(-np.log10(np.divide(spectra_3[i], r_spectrum)))\n",
    "\n",
    "abs_df_3 = pd.DataFrame(abs_spectra, columns=wavelengths)\n",
    "abs_df_3[\"Name\"] = names_3\n",
    "abs_df_3[\"Brix Values\"] = brix_3\n",
    "abs_df_3[\"Group\"] = groups_3\n",
    "\n",
    "abs_df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers - Negative absorbance values and extreme brix values\n",
    "\n",
    "abs_df_noisy = pd.concat([abs_df_1, abs_df_2, abs_df_3], ignore_index=True)\n",
    "\n",
    "abs_df_noisy = abs_df_noisy[abs_df_noisy['900 nm'] > 0]\n",
    "abs_df_noisy = abs_df_noisy[abs_df_noisy['730 nm'] > 0]\n",
    "abs_df_noisy = abs_df_noisy[abs_df_noisy['Brix Values'] < 18]\n",
    "\n",
    "abs_df_noisy.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_df_noisy.to_csv(\"C:\\\\Users\\\\argan\\\\OneDrive\\\\Desktop\\\\DDP\\\\Final Data\\\\NoisyAbs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 21)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_df_noisy.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising - Sample Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_df_1.drop(columns=['Name'], inplace=True)\n",
    "abs_df_2.drop(columns=['Name'], inplace=True)\n",
    "abs_df_3.drop(columns=['Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 19)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing outliers - Negative absorbance values and extreme brix values\n",
    "\n",
    "abs_df_1 = abs_df_1[abs_df_1['900 nm'] > 0]\n",
    "abs_df_1 = abs_df_1[abs_df_1['730 nm'] > 0]\n",
    "abs_df_1 = abs_df_1[abs_df_1['Brix Values'] < 18]\n",
    "abs_df_1.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Sample averaging\n",
    "\n",
    "abs_df_mean_grp_1 = abs_df_1.groupby(['Group']).mean()\n",
    "\n",
    "abs_df_mean_1 = abs_df_mean_grp_1.reset_index(drop=True)\n",
    "\n",
    "abs_df_mean_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 19)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing outliers - Negative absorbance values and extreme brix values\n",
    "\n",
    "abs_df_2 = abs_df_2[abs_df_2['900 nm'] > 0]\n",
    "abs_df_2 = abs_df_2[abs_df_2['730 nm'] > 0]\n",
    "abs_df_2 = abs_df_2[abs_df_2['Brix Values'] < 18]\n",
    "abs_df_2.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Sample averaging\n",
    "\n",
    "abs_df_mean_grp_2 = abs_df_2.groupby(['Group']).mean()\n",
    "\n",
    "abs_df_mean_2 = abs_df_mean_grp_2.reset_index(drop=True)\n",
    "\n",
    "abs_df_mean_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 19)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing outliers - Negative absorbance values and extreme brix values\n",
    "\n",
    "abs_df_3 = abs_df_3[abs_df_3['900 nm'] > 0]\n",
    "abs_df_3 = abs_df_3[abs_df_3['730 nm'] > 0]\n",
    "abs_df_3 = abs_df_3[abs_df_3['Brix Values'] < 18]\n",
    "abs_df_3.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Sample averaging\n",
    "\n",
    "abs_df_mean_grp_3 = abs_df_3.groupby(['Group']).mean()\n",
    "\n",
    "abs_df_mean_3 = abs_df_mean_grp_3.reset_index(drop=True)\n",
    "\n",
    "abs_df_mean_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging\n",
    "\n",
    "abs_df = pd.concat([abs_df_mean_1, abs_df_mean_2, abs_df_mean_3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_df.to_csv(\"C:\\\\Users\\\\argan\\\\OneDrive\\\\Desktop\\\\DDP\\\\Final Data\\\\AvgAbs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c23796a1c2dd51a8797384db4b6b3c42cf1d6cdff572e4ce6333ca4280b9e41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
